{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0aca10-259a-42f7-9a72-138a966c6f53",
   "metadata": {},
   "source": [
    "# Bai tap thuc hanh ex2_MissingValues.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8839065-d166-4702-8c24-680768455d3b",
   "metadata": {},
   "source": [
    "## Tutorial 7b: Data Imputation\n",
    "This covers:\n",
    "\n",
    "- The deletion approach\n",
    "  - Deleting the incomplete features\n",
    "  - Deleting the incomplete instances \n",
    "- pandas\n",
    "  - Simple imputation using pandas\n",
    "  - Interpolation imputation using pandas\n",
    "- sklearn\n",
    "  - Simple imputation using sklearn\n",
    "  - KNN-based imputation using skearn\n",
    "  - Iterative imputation using skearn\n",
    "- Applying the learned models to incomplete test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1cd14a1-2f5d-4fae-b4ab-dc00bce2f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be95ec4-f4eb-4648-b4f5-d3b778ec07d5",
   "metadata": {},
   "source": [
    "## Loading and exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a638be-fda6-4d0b-8a10-db5ed4afd485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Or load titanic data that are alraedy split into train and test data sets according to https://www.kaggle.com/c/titanic/data\n",
    "# But the test data of kaggle does not have labels\n",
    "# Therefore we will load  the whole data from a data repository then split it latter\n",
    "titanic_data = pd.read_csv(\"https://www.openml.org/data/get_csv/16826755/phpMYEkMl.csv\", na_values=['?']) #yo\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99249d-a7d6-4a6f-bafd-3daffc7c1e1e",
   "metadata": {},
   "source": [
    "### Values considered “missing”\n",
    "\n",
    "There are many ways to represent missing values in both the dataset file and the python pandas.\n",
    "\n",
    "Missing values in the data might be blank entries, or '?', or something else that data collecters agreed on to represent unobserved data. In this case it is '?' -- knowing this, we tell pandas what to consider as missing values via na_values=['?'].\n",
    "\n",
    "At the \"other end\", pandas can represent missing values in several different ways. As can be seen above, \"NaN\" is the default missing value marker, however, we need to be able to easily detect this value with data of different types: floating point, integer, boolean, and general object. In many cases, however, some other forms can refer to missing values such as None “missing” or “not available”, “NA\", or (-)inf ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021f4862-5a36-45ae-84ec-dfafd6091681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\admin\\anaconda3\\envs\\ml\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in c:\\users\\admin\\anaconda3\\envs\\ml\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\admin\\anaconda3\\envs\\ml\\lib\\site-packages (from scikit-learn==1.3.0) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\anaconda3\\envs\\ml\\lib\\site-packages (from scikit-learn==1.3.0) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\ml\\lib\\site-packages (from scikit-learn==1.3.0) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4 scikit-learn==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b37a33c3-7fd8-4516-8474-3688b2f02cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop some features that we will not consider here.\n",
    "titanic_data.drop(['name','ticket', 'embarked', 'boat' ,'body' ,'home.dest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea36417-ab86-49d2-a77a-d9975336547a",
   "metadata": {},
   "source": [
    "Now we will split the data to train and test subsets as ONLY the training data will be used to learn the imputers then the learnt models are applied to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08b35740-4327-4842-ae5b-cebe43a36ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=titanic_data['survived']\n",
    "X=titanic_data.drop(['survived'], axis=1)\n",
    "X_titanic_train, X_titanic_test, y_titanic_train, y_titanic_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d71d5ea-730a-4e29-bea8-50b55ffcdaff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'male'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_7540\\306798276.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Now if we perform classification it might not work for most classifiers\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m sklearn.ensemble \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m      3\u001b[39m classifier = RandomForestClassifier()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#classifier=SVC()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m classifier.fit(X_titanic_train, y_titanic_train)\n",
      "\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1147\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1148\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1149\u001b[39m                 )\n\u001b[32m   1150\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1151\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    344\u001b[39m         \"\"\"\n\u001b[32m    345\u001b[39m         \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[32m    346\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    347\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"sparse multilabel-indicator for y is not supported.\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m         X, y = self._validate_data(\n\u001b[32m    349\u001b[39m             X, y, multi_output=\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse=\u001b[33m\"csc\"\u001b[39m, dtype=DTYPE\n\u001b[32m    350\u001b[39m         )\n\u001b[32m    351\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    617\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m    618\u001b[39m                     check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m    619\u001b[39m                 y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m    620\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m                 X, y = check_X_y(X, y, **check_params)\n\u001b[32m    622\u001b[39m             out = X, y\n\u001b[32m    623\u001b[39m \n\u001b[32m    624\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1143\u001b[39m         raise ValueError(\n\u001b[32m   1144\u001b[39m             \u001b[33mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[39m\n\u001b[32m   1145\u001b[39m         )\n\u001b[32m   1146\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     X = check_array(\n\u001b[32m   1148\u001b[39m         X,\n\u001b[32m   1149\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1150\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    914\u001b[39m                         )\n\u001b[32m    915\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    916\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m    919\u001b[39m                 raise ValueError(\n\u001b[32m    920\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m    921\u001b[39m                 ) from complex_warning\n",
      "\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp)\u001b[39m\n\u001b[32m    376\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    377\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    378\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    379\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    381\u001b[39m \n\u001b[32m    382\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    383\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'male'"
     ]
    }
   ],
   "source": [
    "#Now if we perform classification it might not work for most classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "#classifier=SVC()\n",
    "classifier.fit(X_titanic_train, y_titanic_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7280bdd3-b764-468d-b70e-a13b6a7f6bcd",
   "metadata": {},
   "source": [
    "### There is a problem that some features contain string values, namely the features \"sex\" and \"cabin\", so lets encode these features (Có một vấn đề là một số đặc trưng (features) chứa giá trị dạng chuỗi, cụ thể là các đặc trưng \"sex\" và \"cabin\", vì vậy chúng ta sẽ mã hóa (encode) các đặc trưng này)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1cfe071-7697-4c1d-9548-cf33f54eb675",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ComplexWarning' from 'numpy.core.numeric' (C:\\Users\\Admin\\anaconda3\\envs\\ml\\Lib\\site-packages\\numpy\\core\\numeric.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# We need the upgraded sklearn to accept the parameters for encoders\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\n\u001b[32m      3\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install -U scikit-learn\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mThe scikit-learn version is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m.format(sklearn.__version__))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\__init__.py:83\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     80\u001b[39m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     81\u001b[39m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     82\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[32m     86\u001b[39m     __all__ = [\n\u001b[32m     87\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    129\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshow_versions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    130\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\base.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\__init__.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msp\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# mypy error: Module 'numpy.core.numeric' has no attribute 'ComplexWarning'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumeric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ComplexWarning' from 'numpy.core.numeric' (C:\\Users\\Admin\\anaconda3\\envs\\ml\\Lib\\site-packages\\numpy\\core\\numeric.py)"
     ]
    }
   ],
   "source": [
    "# We need the upgraded sklearn to accept the parameters for encoders\n",
    "import sklearn\n",
    "!pip install -U scikit-learn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c38c65-0389-4bb3-b4d4-1117d80ea617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7540\\3871288400.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_titanic_train_encoded['cabin'].replace(cabin_nan_code,np.nan,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Encoding categorical features with preserving the missing values in incomplete features\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder_sex = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value=np.nan)\n",
    "X_titanic_train_encoded=X_titanic_train.copy()\n",
    "X_titanic_train_encoded['sex'] = encoder_sex.fit_transform(X_titanic_train_encoded['sex'].values.reshape(-1, 1))\n",
    "\n",
    "#Now lets encode the incomplete Cabin feature\n",
    "encoder_cabin = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value=np.nan) #You can use the same encoder for both but we use two for the sake of clarfication\n",
    "X_titanic_train_encoded['cabin'] = encoder_cabin.fit_transform(X_titanic_train_encoded['cabin'].values.reshape(-1, 1).astype(str))\n",
    "#get the code of the \"nan\" value for the cabin categorical feature\n",
    "cabin_nan_code=encoder_cabin.transform([['nan']])[0][0]\n",
    "#print(cabin_nan_code)\n",
    "#Now, retrive the nan values to be missing in the encoded data\n",
    "X_titanic_train_encoded['cabin'].replace(cabin_nan_code,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01de7ad3-c104-430c-925b-1614ea128adb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# As the data has no strings/object snow, let's try performing classification using the encoded data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_titanic_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_titanic_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1144\u001b[39m     estimator._validate_params()\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1147\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1148\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1149\u001b[39m     )\n\u001b[32m   1150\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    352\u001b[39m     sample_weight = _check_sample_weight(sample_weight, X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\base.py:621\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    619\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m     out = X, y\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1142\u001b[39m         estimator_name = _check_estimator_name(estimator)\n\u001b[32m   1143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1144\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1145\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1163\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1165\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    954\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    955\u001b[39m             % (array.ndim, estimator_name)\n\u001b[32m    956\u001b[39m         )\n\u001b[32m    958\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples > \u001b[32m0\u001b[39m:\n\u001b[32m    967\u001b[39m     n_samples = _num_samples(array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    159\u001b[39m     msg_err += (\n\u001b[32m    160\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    171\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    172\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# As the data has no strings/object snow, let's try performing classification using the encoded data\n",
    "classifier.fit(X_titanic_train_encoded, y_titanic_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6960999-3974-4ea4-a742-8e0fae60f9ef",
   "metadata": {},
   "source": [
    "## Note the error:ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
    "We need to handle the missing values before performing the classification.\n",
    "\n",
    "Lets show the number of missing values in each feature of the encoded train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f18f232-24ea-4f7a-a078-a7d0c962bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values \n",
      "pclass      0\n",
      "sex         0\n",
      "age       187\n",
      "sibsp       0\n",
      "parch       0\n",
      "fare        1\n",
      "cabin     712\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of missing values \")\n",
    "print(X_titanic_train_encoded.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f55c31f-bcdb-4f7a-bc1f-36268681c85b",
   "metadata": {},
   "source": [
    "We have three incomplete features \"age\", \"fare\", and \"cabin\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4a5d08-d3b3-4ccb-8919-4bfff3a75e85",
   "metadata": {},
   "source": [
    "## The deletion approach\n",
    "### Deleting the incomplete features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d24a245-9e1a-491d-9fe9-5b2e187f881b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>916 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex  sibsp  parch\n",
       "1214       3  1.0      0      0\n",
       "677        3  1.0      0      0\n",
       "534        2  0.0      0      0\n",
       "1174       3  0.0      8      2\n",
       "864        3  0.0      0      0\n",
       "...      ...  ...    ...    ...\n",
       "1095       3  0.0      0      0\n",
       "1130       3  0.0      0      0\n",
       "1294       3  1.0      0      0\n",
       "860        3  0.0      0      0\n",
       "1126       3  0.0      0      0\n",
       "\n",
       "[916 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_train_complete=X_titanic_train_encoded.copy()\n",
    "X_titanic_train_complete.dropna(axis=1, inplace=True)\n",
    "X_titanic_train_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73c079e8-e87f-4cf0-9814-00c187b246d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass    0\n",
      "sex       0\n",
      "sibsp     0\n",
      "parch     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check the number of missing values\n",
    "print(X_titanic_train_complete.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98efd4f2-c212-4551-b0a1-4eeb5b6cfe37",
   "metadata": {},
   "source": [
    "### Deleting the incomplete instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09c91e39-b4f5-453f-b38f-1b430545341b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  sex   age  sibsp  parch      fare  cabin\n",
       "39        1  1.0  48.0      0      0   50.4958   14.0\n",
       "30        1  1.0  45.0      0      0   35.5000  145.0\n",
       "242       1  0.0  33.0      0      0   27.7208    0.0\n",
       "136       1  1.0  53.0      0      0   28.5000   68.0\n",
       "3         1  1.0  30.0      1      2  151.5500   61.0\n",
       "..      ...  ...   ...    ...    ...       ...    ...\n",
       "189       1  1.0  29.0      0      0   30.0000  113.0\n",
       "252       1  1.0  61.0      1      3  262.3750   35.0\n",
       "21        1  0.0  47.0      1      1   52.5542  101.0\n",
       "276       1  1.0  57.0      1      0  146.5208   42.0\n",
       "343       2  1.0  34.0      0      0   13.0000  112.0\n",
       "\n",
       "[186 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_train_complete=X_titanic_train_encoded.copy()\n",
    "X_titanic_train_complete.dropna(axis=0, inplace=True)\n",
    "#The difference is axis=0 instead of 1\n",
    "X_titanic_train_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dad04d-3374-4cb1-8402-db91e8c03e0e",
   "metadata": {},
   "source": [
    "## Notice the reduction in the number of instances\n",
    "Another important point for the instance deletion approach is that there is a need to remove the target values (from y_train) that correspond to the incomplete (deleted) data instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87ec4c8c-ddc7-4a5a-9bb2-e7ff21cafa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass    0\n",
      "sex       0\n",
      "age       0\n",
      "sibsp     0\n",
      "parch     0\n",
      "fare      0\n",
      "cabin     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check the number of missing values\n",
    "print(X_titanic_train_complete.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ced19-23e7-4586-81d0-7afa3f508348",
   "metadata": {},
   "source": [
    "The deletion approach has several drawbacks. It reduces the availlable data, which limits the learning ability, especially when there are many missing values.\n",
    "\n",
    "Furthermore, the approach of deleting incomplete instances is not practical for test data: we really want to know the answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e622d-b134-471f-b588-7737e130d1bc",
   "metadata": {},
   "source": [
    "## Imputation using pandas\n",
    "### Simple imputation (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64f288e8-3dd1-4ecc-aeda-cd341b78cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass    0\n",
      "sex       0\n",
      "age       0\n",
      "sibsp     0\n",
      "parch     0\n",
      "fare      0\n",
      "cabin     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Mean for numeric values\n",
    "X_titanic_data_complete=X_titanic_train_encoded.copy()\n",
    "X_titanic_data_complete['age']=X_titanic_data_complete['age'].fillna(X_titanic_data_complete['age'].mean())\n",
    "X_titanic_data_complete['fare']=X_titanic_data_complete['fare'].fillna(X_titanic_data_complete['fare'].mean())\n",
    "X_titanic_data_complete['cabin']=X_titanic_data_complete['cabin'].fillna(X_titanic_data_complete['cabin'].mean())\n",
    "# Show the number of missing values\n",
    "print(X_titanic_data_complete.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "530d7696-a22b-4178-8b5e-bea81ca661a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.102309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>73.27451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>73.27451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>73.27451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.102309</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>73.27451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>73.27451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex        age  sibsp  parch     fare     cabin\n",
       "1214       3  1.0  29.102309      0      0   8.6625  73.27451\n",
       "677        3  1.0  26.000000      0      0   7.8958  73.27451\n",
       "534        2  0.0  19.000000      0      0  26.0000  73.27451\n",
       "1174       3  0.0  29.102309      8      2  69.5500  73.27451\n",
       "864        3  0.0  28.000000      0      0   7.7750  73.27451"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_data_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7a089-7bad-4868-9717-52b807ec1a8b",
   "metadata": {},
   "source": [
    "## \"interpolation\" (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a267e546-360f-4790-aff7-e45cd01bd212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass    0\n",
      "sex       0\n",
      "age       0\n",
      "sibsp     0\n",
      "parch     0\n",
      "fare      0\n",
      "cabin     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_titanic_data_complete = X_titanic_train_encoded.copy()\n",
    "X_titanic_data_complete = X_titanic_data_complete.interpolate()\n",
    "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
    "X_titanic_train_complete = pd.DataFrame(X_titanic_train_complete)\n",
    "print(X_titanic_train_complete.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea3e24-bd3d-48eb-b894-b932bb3d7c62",
   "metadata": {},
   "source": [
    "## Imputation using sklearn\n",
    "### Simple imputation (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b16fd1aa-d7d6-4904-bd22-dd37067512f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values :\n",
      " pclass    0\n",
      "sex       0\n",
      "age       0\n",
      "sibsp     0\n",
      "parch     0\n",
      "fare      0\n",
      "cabin     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer()\n",
    "X_titanic_train_complete = imputer.fit_transform(X_titanic_train_encoded)\n",
    "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
    "X_titanic_train_complete=pd.DataFrame(X_titanic_train_complete, columns=X_titanic_train_encoded.columns)\n",
    "print(\"The number of missing values :\\n\", X_titanic_train_complete.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa580e-1fc0-4d79-889d-37368d8de380",
   "metadata": {},
   "source": [
    "## kNN imputer (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d1f0578-71eb-4db4-b3d4-6af34a39b152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values :\n",
      " pclass    0\n",
      "sex       0\n",
      "age       0\n",
      "sibsp     0\n",
      "parch     0\n",
      "fare      0\n",
      "cabin     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer()\n",
    "X_titanic_train_complete = imputer.fit_transform(X_titanic_train_encoded)\n",
    "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
    "X_titanic_train_complete=pd.DataFrame(X_titanic_train_complete, columns=X_titanic_train_encoded.columns)\n",
    "print(\"The number of missing values :\\n\", X_titanic_train_complete.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab33f7b7-f554-4d74-8d70-fae127a63110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The default k for the KNN imputer is 5, you can change it as follows:\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "# etc etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655975a-9233-4f89-8ea5-92150e220337",
   "metadata": {},
   "source": [
    "## Iterative Imputer (sklearn)\n",
    "\n",
    "Note this is sklearn's implementation of a method originally known as \"MICE\" -- see lecture 2 from this week for an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50e930d1-8c4d-456e-8a8a-c9d02a14292c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values :\n",
      " pclass    0\n",
      "sex       0\n",
      "age       0\n",
      "sibsp     0\n",
      "parch     0\n",
      "fare      0\n",
      "cabin     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imputer = IterativeImputer()\n",
    "X_titanic_train_complete = imputer.fit_transform(X_titanic_train_encoded)\n",
    "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
    "X_titanic_train_complete=pd.DataFrame(X_titanic_train_complete, columns=X_titanic_train_encoded.columns)\n",
    "print(\"The number of missing values :\\n\", X_titanic_train_complete.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67146a14-db67-45e9-b89a-a0c8addf7b5a",
   "metadata": {},
   "source": [
    "You can reset the default parameters of the iterative imputer. For example, you can set the number of iterations. Moreover, you can specify the estimator for estimating the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f85074eb-3116-4dcb-bf53-699f109cfc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values :\n",
      " pclass    0\n",
      "sex       0\n",
      "age       0\n",
      "sibsp     0\n",
      "parch     0\n",
      "fare      0\n",
      "cabin     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:796: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Lets use DT as an estimator\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "imputer = IterativeImputer(estimator=DecisionTreeRegressor())\n",
    "X_titanic_train_complete = imputer.fit_transform(X_titanic_train_encoded)\n",
    "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
    "X_titanic_train_complete=pd.DataFrame(X_titanic_train_complete, columns=X_titanic_train_encoded.columns)\n",
    "print(\"The number of missing values :\\n\", X_titanic_train_complete.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1a9bb-e82e-4c8e-8425-0933fe9222e2",
   "metadata": {},
   "source": [
    "## Applying the learned models to incomplete test data\n",
    "First, apply the encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8aa204c-7ff6-4355-8ec7-2e947627031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7540\\1619151247.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_titanic_test_encoded['cabin'].replace(cabin_nan_code,np.nan,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#The learnt encoder_sex should be used to encode the test data, NOTE there is NO fit here, just transform\n",
    "X_titanic_test_encoded=X_titanic_test.copy()\n",
    "X_titanic_test_encoded['sex'] = encoder_sex.transform(X_titanic_test_encoded['sex'].values.reshape(-1, 1))\n",
    "\n",
    "#The learnt encoder2 should be used to encode the test data, NOTE there is NO fit here, just transform\n",
    "X_titanic_test_encoded['cabin'] = encoder_cabin.transform(X_titanic_test_encoded['cabin'].values.reshape(-1, 1).astype(str))\n",
    "#Now, retrive the nan values to be missing in the encoded data\n",
    "X_titanic_test_encoded['cabin'].replace(cabin_nan_code,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c08b3-21ef-4711-ba27-bed387cd3bfc",
   "metadata": {},
   "source": [
    "Second, use the learned imputer to estimate the missing values in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc2cbdb9-7007-4ab4-9771-76fe80197f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values in the test data before imputation :\n",
      " pclass      0\n",
      "sex         0\n",
      "age        76\n",
      "sibsp       0\n",
      "parch       0\n",
      "fare        0\n",
      "cabin     349\n",
      "dtype: int64\n",
      "The number of missing values in the test data after imputation :\n",
      " pclass    0\n",
      "sex       0\n",
      "age       0\n",
      "sibsp     0\n",
      "parch     0\n",
      "fare      0\n",
      "cabin     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of missing values in the test data before imputation :\\n\", X_titanic_test_encoded.isnull().sum())\n",
    "X_titanic_test_complete = imputer.transform(X_titanic_test_encoded)\n",
    "X_titanic_test_complete=pd.DataFrame(X_titanic_test_complete, columns=X_titanic_test_encoded.columns)\n",
    "print(\"The number of missing values in the test data after imputation :\\n\", X_titanic_test_complete.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328446b0-46c7-41f2-8d2b-21c52a41f17d",
   "metadata": {},
   "source": [
    "Finally, we can perform the classification using the imputed complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97ecafd8-e27e-4088-a509-e709ac67b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score after imputation =  0.7278481012658228\n"
     ]
    }
   ],
   "source": [
    "#We use f-measure because the classes are not balanced\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state=0)\n",
    "#classifier=SVC()\n",
    "classifier.fit(X_titanic_train_complete, y_titanic_train)\n",
    "print(\"F1 score after imputation = \", f1_score(classifier.predict(X_titanic_test_complete), y_titanic_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec2855-8f29-4dc4-a6d9-a80cfa0a2669",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
